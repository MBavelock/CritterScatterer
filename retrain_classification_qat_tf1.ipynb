{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrain_classification_qat_tf1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "license"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "license"
      },
      "source": [
        "##### *Copyright 2020 Google LLC*\n",
        "*Licensed under the Apache License, Version 2.0 (the \"License\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "rKwqeqWBXANA"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRTa3Ee15WsJ"
      },
      "source": [
        "# Retrain a detection model for Edge TPU with quant-aware training (TF 1.12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaX0smDP7xQY"
      },
      "source": [
        "This notebook uses a set of TensorFlow training scripts to perform transfer-learning on a quantization-aware object detection model and then convert it for compatibility with the [Edge TPU](https://coral.ai/products/).\n",
        "\n",
        "Specifically, this tutorial shows you how to retrain a MobileNet V1 SSD model so that it detects two pets: Abyssinian cats and American Bulldogs (from the [Oxford-IIIT Pets Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)), using TensorFlow r1.12.\n",
        "\n",
        "Beware that, compared to a desktop computer, this training can take *a lot* longer in Colab because Colab provides limited resources for long-running operations. So you'll likely see faster training speeds if you [connect this notebook to a local runtime](https://research.google.com/colaboratory/local-runtimes.html), or instead follow the [tutorial to run this training in Docker](https://coral.ai/docs/edgetpu/retrain-detection/) (which includes more documentation about this process)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTCYQg_be8C0"
      },
      "source": [
        "## Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxAceTA36NKQ"
      },
      "source": [
        "! pip3 uninstall tensorflow -y\n",
        "#! pip3 install tensorflow==1.12\n",
        "! pip3 install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ebgg83X9oTh"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5i4xSgWkKi1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpTmoIxuranU"
      },
      "source": [
        "## Clone the model and training repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_zobAPP8J9Y"
      },
      "source": [
        "! git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4Yftz8HsilF"
      },
      "source": [
        "! cd models && git checkout f788046ca876a8820e05b0b48c1fc2e16b0955bc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy4Q_Uva9eii"
      },
      "source": [
        "! git clone https://github.com/google-coral/tutorials.git\n",
        "\n",
        "! cp -r tutorials/docker/object_detection/scripts/* models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iv-kpe2Xe69"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImucOu0qgMv_"
      },
      "source": [
        "For details, see https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJEhkUxlfhh4"
      },
      "source": [
        "! apt-get install -y python python-tk\n",
        "! pip install Cython contextlib2 pillow lxml jupyter matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45oRT7h6XhgP"
      },
      "source": [
        "# Get protoc 3.0.0, rather than the old version already in the container\n",
        "! wget https://www.github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
        "! unzip protoc-3.0.0-linux-x86_64.zip -d proto3\n",
        "! mkdir -p local/bin && mkdir -p local/include\n",
        "! mv proto3/bin/* local/bin\n",
        "! mv proto3/include/* local/include\n",
        "! rm -rf proto3 protoc-3.0.0-linux-x86_64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snUGUfruaTFa"
      },
      "source": [
        "# Install pycocoapi\n",
        "! git clone --depth 1 https://github.com/cocodataset/cocoapi.git\n",
        "! (cd cocoapi/PythonAPI && make -j8)\n",
        "! cp -r cocoapi/PythonAPI/pycocotools/ /content/models/research/\n",
        "! rm -rf cocoapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz0nN7eVeXo6"
      },
      "source": [
        "# Run protoc on the object detection repo (generate .py files from .proto)\n",
        "% cd /content/models/research/\n",
        "#! ../../local/bin/protoc object_detection/protos/*.proto --python_out=.\n",
        "! /content/local/bin/protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53D-U0_gg8VB"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research:/content/models/research/slim\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpXtNIFxkms2"
      },
      "source": [
        "Just to verify everything is correctly set up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftH0svNxgUm4"
      },
      "source": [
        "! python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IweNl64rridS"
      },
      "source": [
        "## Convert training data to TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_eOd08untOM"
      },
      "source": [
        "\n",
        "# Import Dataset from Github\n",
        "repo_url = 'https://github.com/MBavelock/object_detection_demo'\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull\n",
        "\n",
        "#Upload Dataset as zip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/gdrive/MyDrive/Dataset/images.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/object_detection_demo/data\")\n",
        "zip_ref.close()\n",
        "\n",
        "#!unzip '/content/gdrive/MyDrive/Critter_Scatterer_-_Senior Design/ECE_458/Dataset/images.zip' -d '/content/object_detection_demo/data'\n",
        "\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
        "\n",
        "# Convert test folder annotation xml files to a single csv.\n",
        "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
        "\n",
        "# Generate `train.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
        "\n",
        "\n",
        "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
        "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
        "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdGWra9PBA-9"
      },
      "source": [
        "To train with different images, read [how to configure your own training data](https://coral.ai/docs/edgetpu/retrain-detection/#configure-your-own-training-data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbz5nKlDAorQ"
      },
      "source": [
        "# in research\n",
        "#OBJ_DET_DIR=\"$PWD\"\n",
        "#LEARN_DIR=\"${OBJ_DET_DIR}/learn_pet\"\n",
        "#DATASET_DIR=\"${LEARN_DIR}/pet\"\n",
        "#CKPT_DIR=\"${LEARN_DIR}/ckpt\"\n",
        "#TRAIN_DIR=\"${LEARN_DIR}/train\"\n",
        "#OUTPUT_DIR=\"${LEARN_DIR}/models\"\n",
        "\n",
        "#! ./prepare_checkpoint_and_dataset.sh --network_type mobilenet_v1_ssd --train_whole_model false\n",
        "\n",
        "### NEED TODO \n",
        "#cp train.record -> /content/models/research/learn_pet/pet/\n",
        "#cp test.record -> /content/models/research/learn_pet/pet/\n",
        "#cp label_map.pbtxt -> /content/models/research/learn_pet/pet/\n",
        "#change configfile to be 12 labels\n",
        "#change configfile to match train.record, test.record, label_map\n",
        "\n",
        "\n",
        "\n",
        "# Download checkpoint for transfer learning\n",
        "! echo 'PREPARING checkpoint...'\n",
        "%mkdir -p /content/models/research/learn_pet\n",
        "%cd /content/models/research/learn_pet\n",
        "! wget -O ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n",
        "! tar zxvf ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n",
        "%rm /content/models/research/learn_pet/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18.tar.gz\n",
        "\n",
        "# Add Config file to dir\n",
        "#! echo 'CHOSING config file...'\n",
        "#%cd /content/models/research\n",
        "#%mkdir -p /content/models/research/learn_pet/ckpt/\n",
        "#%cp configs/pipeline_mobilenet_v1_ssd_retrain_last_few_layers.config /content/models/research/learn_pet/ckpt/pipeline.config\n",
        "\n",
        "# Edit Config File\n",
        "import re\n",
        "#pipeline_fname = '/content/models/research/learn_pet/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18/pipeline.config'\n",
        "pipeline_fname = '/content/object_detection_demo/pipeline.config'\n",
        "train_record_fname = train_record_fname\n",
        "test_record_fname = test_record_fname\n",
        "label_map_pbtxt_fname = label_map_pbtxt_fname\n",
        "fine_tune_checkpoint = os.path.join('/content/models/research/learn_pet/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18/', \"model.ckpt\")\n",
        "##### Copy old check point if you want to keep training\n",
        "#%mkdir \"/content/models/research/learn_pet/finetuning\"\n",
        "#%cp -av \"/content/gdrive/MyDrive/TFLite/trainingckpt/\" \"/content/models/research/learn_pet/finetuning/\"\n",
        "#%mv \"/content/models/research/learn_pet/model.ckpt-50000.data-00000-of-00001\" \"/content/models/research/learn_pet/model.ckpt\"\n",
        "#fine_tune_checkpoint = \"/content/models/research/learn_pet/finetuning/trainingckpt/model.ckpt-50000\"\n",
        "\n",
        "batch_size = 12\n",
        "num_steps = 50000\n",
        "num_classes = 12\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Set max_negatives_per_positive: maximum number of negatives \n",
        "    # to retain for each positive anchor. By default, num_negatives_per_positive is None, which \n",
        "    # means that we do not enforce a prespecified negative:positive ratio. Note also that \n",
        "    # num_negatives_per_positives can be a float (and will be converted to be a float even if it is \n",
        "    # passed in otherwise).\n",
        "    s = re.sub('max_negatives_per_positive: [0-9]+',\n",
        "               'max_negatives_per_positive: {}'.format(3), s)\n",
        "\n",
        "    # Set min_negatives_per_image: minimum number of negative anchors to \n",
        "    # sample for a given image. Setting this to a positive number allows sampling negatives in an image \n",
        "    # without any positive anchors and thus not biased towards at least one detection per image.\n",
        "    s = re.sub('min_negatives_per_image: [0-9]+',\n",
        "               'min_negatives_per_image: {}'.format(1), s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "\n",
        "!cat {pipeline_fname}\n",
        "\n",
        "#%cp \"/content/gdrive/MyDrive/TFLite/test/test.record\" \"/content/models/research/learn_pet/\"\n",
        "#%cp \"/content/gdrive/MyDrive/TFLite/train/train.record\" \"/content/models/research/learn_pet/\"\n",
        "#%cp \"/content/gdrive/MyDrive/TFLite/train/label_map.pbtxt\" \"/content/models/research/learn_pet/\"\n",
        "\n",
        "#! echo 'PREPARING dataset'\n",
        "#%mkdir -p /content/models/research/learn_pet/pet\n",
        "#%cd /content/models/research/learn_pet/pet\n",
        "\n",
        "#! echo 'PREPARING label map...'\n",
        "#%cd /content/models/research\n",
        "#%cp object_detection/data/pet_label_map.pbtxt /content/models/research/learn_pet/pet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg3oMLs1rus7"
      },
      "source": [
        "## Perform transfer-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2FIkwyhW8IX"
      },
      "source": [
        "The following script takes several hours to finish in Colab. (You can shorten by reducing the steps, but that reduces the final accuracy.)\n",
        "\n",
        "If you didn't already select \"Run all\" then you should run all remaining cells now. That will ensure the rest of the notebook completes while you are away, avoiding the chance that the Colab runtime times-out and you lose the training data before you download the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NkqCq8g9A5M"
      },
      "source": [
        "#%env NUM_TRAINING_STEPS=500\n",
        "#NUM_TRAINING_STEPS=num_steps\n",
        "#%env NUM_EVAL_STEPS=100\n",
        "#NUM_EVAL_STEPS=num_steps/100\n",
        "\n",
        "# If you're retraining the whole model, we suggest thes values:\n",
        "# %env NUM_TRAINING_STEPS=50000\n",
        "# %env NUM_EVAL_STEPS=2000\n",
        "\n",
        "\n",
        "%mkdir -p /content/models/research/learn_pet/train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISp0a9D7Ap4A"
      },
      "source": [
        "# https://github.com/google-coral/tutorials/tree/master/docker/object_detection/scripts\n",
        "#! ./retrain_detection_model.sh --num_training_steps $NUM_TRAINING_STEPS --num_eval_steps $NUM_EVAL_STEPS\n",
        "\n",
        "! python /content/models/research/object_detection/model_main.py \\\n",
        "  --pipeline_config_path=\"/content/object_detection_demo/pipeline.config\" \\\n",
        "  --model_dir=\"/content/models/research/learn_pet/train\" \\\n",
        "  --num_train_steps=100000 \\\n",
        "  --num_eval_steps=2000\n",
        "\n",
        "  # 500\n",
        "  # 100\n",
        "  \n",
        "# If not using custome pipefile.config\n",
        "# \"/content/models/research/learn_pet/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18/pipeline.config\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX1DW1JGiMjt"
      },
      "source": [
        "# Download\n",
        "!cp -av /content/models/research/learn_pet/train /content/gdrive/MyDrive/TFLite/trainingckpt_413\n",
        "!cp /content/models/research/learn_pet/ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18/pipeline.config /content/gdrive/MyDrive/TFLite/trainingckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1jjZIKpmbyB"
      },
      "source": [
        "As training progresses, you can see new checkpoint files appear in the `models/research/learn_pet/train/` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quv4hQWNhaAH"
      },
      "source": [
        "## Compile for the Edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9z4ctFiwp6"
      },
      "source": [
        "#! ./convert_checkpoint_to_edgetpu_tflite.sh --checkpoint_num $NUM_TRAINING_STEPS\n",
        "\n",
        "\n",
        "#echo \"GENERATING label file...\"\n",
        "#echo \"0 Abyssinian\" >> \"${OUTPUT_DIR}/labels.txt\"\n",
        "#echo \"1 american_bulldog\" >> \"${OUTPUT_DIR}/labels.txt\"\n",
        "\n",
        "!echo \"EXPORTING frozen graph from checkpoint...\"\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "  --pipeline_config_path=\"/content/object_detection_demo/pipeline.config\" \\\n",
        "  --trained_checkpoint_prefix=\"/content/models/research/learn_pet/train/model.ckpt-100000\" \\\n",
        "  --output_directory=\"/content/\" \\\n",
        "  --add_postprocessing_op=true\n",
        "\n",
        "!echo \"CONVERTING frozen graph to TF Lite file...\"\n",
        "!tflite_convert \\\n",
        "  --output_file=\"/content/output_tflite_graph.tflite\" \\\n",
        "  --graph_def_file=\"/content/tflite_graph.pb\" \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --input_arrays=\"normalized_input_image_tensor\" \\\n",
        "  --output_arrays=\"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\" \\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=128 \\\n",
        "  --input_shapes=1,300,300,3 \\\n",
        "  --change_concat_input_ranges=false \\\n",
        "  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n",
        "  --allow_custom_ops\n",
        "\n",
        "!echo \"TFLite graph generated at /content/output_tflite_graph.tflite\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RxtslKJf2td"
      },
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9doQdA2QkPnV"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUhhhMdkbrY"
      },
      "source": [
        "%cd /content/\n",
        "!edgetpu_compiler -s output_tflite_graph.tflite\n",
        "\n",
        "# Download\n",
        "!cp /content/output_tflite_graph.tflite /content/gdrive/MyDrive/TFLite/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPt8RdopXsZv"
      },
      "source": [
        "Download the files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuE-CnPkdfI"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('output_tflite_graph_edgetpu.tflite')\n",
        "#files.download('labels.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qOCP3mXXvsm"
      },
      "source": [
        "If you get a \"Failed to fetch\" error here, it's probably because the files weren't done saving. So just wait a moment and try again.\n",
        "\n",
        "Also look out for a browser popup that might need approval to download the files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZTwG7nhm0C"
      },
      "source": [
        "## Run the model on the Edge TPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwywT4ZpQjLf"
      },
      "source": [
        "You can now run the model on your Coral device with acceleration on the Edge TPU.\n",
        "\n",
        "To get started, try using [this code for object detection with the TensorFlow Lite API](https://github.com/google-coral/tflite/tree/master/python/examples/detection). Just follow the instructions on that page to set up your device, copy the `output_tflite_graph_edgetpu.tflite` and `labels.txt` files to your Coral Dev Board or device with a Coral Accelerator, and pass it a photo to see the detected objects.\n",
        "\n",
        "Check out more examples for running inference at [coral.ai/examples](https://coral.ai/examples/#code-examples/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2tyWn83VOAF"
      },
      "source": [
        "## Implementation details\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5tKMtKVVDps"
      },
      "source": [
        "\n",
        "All the scripts used in this notebook come from the following locations:<br>\n",
        "+  https://github.com/google-coral/tutorials/tree/master/docker/object_detection/scripts\n",
        "+  https://github.com/tensorflow/models/tree/r1.13.0/research/object_detection/\n",
        "\n",
        "More explanation of the steps in this tutorial is available at\n",
        "https://coral.ai/docs/edgetpu/retrain-detection/."
      ]
    }
  ]
}